{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# file_path = \"C:/Users/tarek/Downloads/m_and_a/data_eur/07_Gross_income_1.xlsx\"\n",
    "file_path = \"C:/Users/tarek/Downloads/project_ma/merged_training_data_side_by_side 2.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "df = pd.read_excel(xls, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to ignore\n",
    "ignore_columns = [\n",
    "    'USABLE_FOR', 'INDUSTRY_CODE', 'SECTOR_CODE', 'DEAL_SIZE', 'OMG_RATIO', 'SECTION',\n",
    "    'USABLE_FOR.1', 'INDUSTRY_CODE.1', 'SECTOR_CODE.1', 'DEAL_SIZE.1', 'OMG_RATIO.1', 'SECTION.1'\n",
    "]\n",
    "\n",
    "# Select features (X) from SELL SIDE\n",
    "X_columns = [col for col in df.columns[:len(df.columns)//2] if col not in ignore_columns]\n",
    "X = df[X_columns]\n",
    "\n",
    "# Select target (y) from BUY SIDE\n",
    "y_columns = [col for col in df.columns[len(df.columns)//2:] if col not in ignore_columns]\n",
    "y = df[y_columns]\n",
    "\n",
    "# Extract only numerical columns from 2019 to 2023 for both X and y\n",
    "X_numerical = X[['SELL_DEC 2019', 'SELL_DEC 2020', 'SELL_DEC 2021', 'SELL_DEC 2022']].astype(float)\n",
    "y_numerical = y[['BUY_DEC 2019']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'SELL_ANNOUNCE_DATE', 'SELL_TARGET', 'SELL_NAME', 'SELL_CURRENCY', 'SELL_INDUSTRY_CODE', 'SELL_SECTOR_CODE', 'SELL_OMG_RATIO', 'SELL_DEC 2019', 'SELL_DEC 2020', 'SELL_DEC 2021', 'SELL_DEC 2022']\n"
     ]
    }
   ],
   "source": [
    "print(X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3686, 4), (3686, 1))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical.shape, y_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SELL_DEC 2019</th>\n",
       "      <th>SELL_DEC 2020</th>\n",
       "      <th>SELL_DEC 2021</th>\n",
       "      <th>SELL_DEC 2022</th>\n",
       "      <th>BUY_DEC 2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SELL_DEC 2019</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988706</td>\n",
       "      <td>0.982541</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.181218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELL_DEC 2020</th>\n",
       "      <td>0.988706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993523</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.178317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELL_DEC 2021</th>\n",
       "      <td>0.982541</td>\n",
       "      <td>0.993523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997490</td>\n",
       "      <td>0.184773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELL_DEC 2022</th>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.997490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY_DEC 2019</th>\n",
       "      <td>0.181218</td>\n",
       "      <td>0.178317</td>\n",
       "      <td>0.184773</td>\n",
       "      <td>0.188265</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SELL_DEC 2019  SELL_DEC 2020  SELL_DEC 2021  SELL_DEC 2022  \\\n",
       "SELL_DEC 2019       1.000000       0.988706       0.982541       0.985979   \n",
       "SELL_DEC 2020       0.988706       1.000000       0.993523       0.993209   \n",
       "SELL_DEC 2021       0.982541       0.993523       1.000000       0.997490   \n",
       "SELL_DEC 2022       0.985979       0.993209       0.997490       1.000000   \n",
       "BUY_DEC 2019        0.181218       0.178317       0.184773       0.188265   \n",
       "\n",
       "               BUY_DEC 2019  \n",
       "SELL_DEC 2019      0.181218  \n",
       "SELL_DEC 2020      0.178317  \n",
       "SELL_DEC 2021      0.184773  \n",
       "SELL_DEC 2022      0.188265  \n",
       "BUY_DEC 2019       1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine both DataFrames side by side\n",
    "combined_df = pd.concat([X_numerical, y_numerical], axis=1)\n",
    "combined_df=combined_df.dropna()\n",
    "combined_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['DEC 2023'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define X (features) and y (target)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m combined_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC 2019\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC 2020\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC 2021\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC 2022\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDEC 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tarek\\Downloads\\CodeChallenge-ML-Engineer-main\\CodeChallenge-ML-Engineer-main\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tarek\\Downloads\\CodeChallenge-ML-Engineer-main\\CodeChallenge-ML-Engineer-main\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tarek\\Downloads\\CodeChallenge-ML-Engineer-main\\CodeChallenge-ML-Engineer-main\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['DEC 2023'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = combined_df[['DEC 2019', 'DEC 2020', 'DEC 2021', 'DEC 2022']]\n",
    "y = combined_df[['DEC 2023']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DEC 2019    DEC 2020    DEC 2021    DEC 2022    DEC 2023\n",
      "0      45.197100   41.663350   15.948880   36.992340   19.631040\n",
      "1     134.976425  158.306234  376.345258  543.896738  615.795786\n",
      "2      -0.007100    0.349315    0.444288    0.559482    0.337463\n",
      "3       0.699360    0.177100    0.089817    0.479000    0.372052\n",
      "4       8.324802  -42.341068  -10.301725  -23.925621  -63.988526\n",
      "...          ...         ...         ...         ...         ...\n",
      "2900    2.599000    3.243000    2.987000    2.866000    3.014000\n",
      "2901   15.754780   13.623800   12.414900   13.923000    2.113020\n",
      "2902    0.202000    0.782000    1.095000    0.382000    0.024000\n",
      "2903    2.888000    3.170000    3.602000    3.037000    2.581000\n",
      "2904   -0.293200   -0.307990    0.081312    0.100352    0.271794\n",
      "\n",
      "[2905 rows x 5 columns]\n",
      "      DEC 2023.1\n",
      "0        478.418\n",
      "1       8735.530\n",
      "2         -6.177\n",
      "3      10481.000\n",
      "4        284.000\n",
      "...          ...\n",
      "3122      67.893\n",
      "3123     138.838\n",
      "3124      -6.177\n",
      "3125     975.000\n",
      "3126      13.152\n",
      "\n",
      "[2905 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_numerical=X_numerical[:2905]\n",
    "print(X_numerical.shape)\n",
    "y_numerical = y_numerical[:2905]\n",
    "print(y_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets (80% training, 20% validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2948, 4) (738, 4) (2948, 1) (738, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:08<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      value__sum_values  value__median  value__mean  value__length  \\\n",
      "0              1.207000       0.308000     0.301750            4.0   \n",
      "1             50.137490      12.737520    12.534372            4.0   \n",
      "2             42.520810      11.110975    10.630203            4.0   \n",
      "3             21.849710       5.595925     5.462427            4.0   \n",
      "4             -0.751565      -0.016043    -0.187891            4.0   \n",
      "...                 ...            ...          ...            ...   \n",
      "2717         234.578170      53.346135    58.644543            4.0   \n",
      "2718           7.457000       2.401000     1.864250            4.0   \n",
      "2719          63.799471      16.140933    15.949868            4.0   \n",
      "2720          -7.633950       0.007475    -1.908487            4.0   \n",
      "2721           6.006120       1.296135     1.501530            4.0   \n",
      "\n",
      "      value__standard_deviation  value__variance  value__root_mean_square  \\\n",
      "0                      0.019992         0.000400                 0.302412   \n",
      "1                      1.777312         3.158837                12.659752   \n",
      "2                      2.481569         6.158182                10.916015   \n",
      "3                      0.711619         0.506402                 5.508586   \n",
      "4                      0.929222         0.863454                 0.948028   \n",
      "...                         ...              ...                      ...   \n",
      "2717                  34.251994      1173.199110                67.914516   \n",
      "2718                   1.338195         1.790767                 2.294819   \n",
      "2719                   0.982087         0.964494                15.980074   \n",
      "2720                   3.333487        11.112135                 3.841153   \n",
      "2721                   0.542868         0.294706                 1.596652   \n",
      "\n",
      "      value__maximum  value__absolute_maximum  value__minimum  \n",
      "0           0.320000                 0.320000        0.271000  \n",
      "1          14.713200                14.713200        9.949250  \n",
      "2          13.433400                13.433400        6.865460  \n",
      "3           6.216560                 6.216560        4.441300  \n",
      "4           0.791520                 1.511000       -1.511000  \n",
      "...              ...                      ...             ...  \n",
      "2717      106.374600               106.374600       21.511300  \n",
      "2718        2.980000                 2.980000       -0.325000  \n",
      "2719       17.112762                17.112762       14.404842  \n",
      "2720        0.033320                 7.682220       -7.682220  \n",
      "2721        2.385900                 2.385900        1.027950  \n",
      "\n",
      "[2722 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as st\n",
    "\n",
    "### 1. Feature Extraction Using tsfresh ###\n",
    "\n",
    "# Convert X_train to long format for tsfresh\n",
    "X_train_long = X_train.copy()\n",
    "X_train_long[\"id\"] = np.arange(len(X_train))  # Assign a unique ID to each row\n",
    "X_train_long = X_train_long.melt(id_vars=[\"id\"], var_name=\"time\", value_name=\"value\")\n",
    "\n",
    "# Extract features\n",
    "extracted_features = extract_features(X_train_long, column_id=\"id\", column_sort=\"time\",\n",
    "                                      default_fc_parameters=MinimalFCParameters())\n",
    "\n",
    "# # Remove NaN features\n",
    "# extracted_features = extracted_features.dropna(axis=1)\n",
    "print(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value__sum_values            0\n",
      "value__median                0\n",
      "value__mean                  0\n",
      "value__length                0\n",
      "value__standard_deviation    0\n",
      "value__variance              0\n",
      "value__root_mean_square      0\n",
      "value__maximum               0\n",
      "value__absolute_maximum      0\n",
      "value__minimum               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure extracted_features has the same index as X_train\n",
    "extracted_features.index = X_train.index  # Align index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DEC 2019   DEC 2020   DEC 2021    DEC 2022  value__sum_values  \\\n",
      "3677   0.319000   0.271000   0.297000    0.320000           1.207000   \n",
      "1421  11.988300   9.949250  13.486740   14.713200          50.137490   \n",
      "2566   6.865460  10.076750  12.145200   13.433400          42.520810   \n",
      "1341   5.160870   4.441300   6.030980    6.216560          21.849710   \n",
      "1169  -1.511000   0.569145   0.791520   -0.601230          -0.751565   \n",
      "...         ...        ...        ...         ...                ...   \n",
      "1158  21.511300  31.214550  75.477720  106.374600         234.578170   \n",
      "1196   2.925000   2.980000   1.877000   -0.325000           7.457000   \n",
      "1374  15.990041  14.404842  17.112762   16.291826          63.799471   \n",
      "897   -7.682220   0.014950   0.000000    0.033320          -7.633950   \n",
      "3430   1.027950   1.086300   1.505970    2.385900           6.006120   \n",
      "\n",
      "      value__median  value__mean  value__length  value__standard_deviation  \\\n",
      "3677       0.308000     0.301750            4.0                   0.019992   \n",
      "1421      12.737520    12.534372            4.0                   1.777312   \n",
      "2566      11.110975    10.630203            4.0                   2.481569   \n",
      "1341       5.595925     5.462427            4.0                   0.711619   \n",
      "1169      -0.016043    -0.187891            4.0                   0.929222   \n",
      "...             ...          ...            ...                        ...   \n",
      "1158      53.346135    58.644543            4.0                  34.251994   \n",
      "1196       2.401000     1.864250            4.0                   1.338195   \n",
      "1374      16.140933    15.949868            4.0                   0.982087   \n",
      "897        0.007475    -1.908487            4.0                   3.333487   \n",
      "3430       1.296135     1.501530            4.0                   0.542868   \n",
      "\n",
      "      value__variance  value__root_mean_square  value__maximum  \\\n",
      "3677         0.000400                 0.302412        0.320000   \n",
      "1421         3.158837                12.659752       14.713200   \n",
      "2566         6.158182                10.916015       13.433400   \n",
      "1341         0.506402                 5.508586        6.216560   \n",
      "1169         0.863454                 0.948028        0.791520   \n",
      "...               ...                      ...             ...   \n",
      "1158      1173.199110                67.914516      106.374600   \n",
      "1196         1.790767                 2.294819        2.980000   \n",
      "1374         0.964494                15.980074       17.112762   \n",
      "897         11.112135                 3.841153        0.033320   \n",
      "3430         0.294706                 1.596652        2.385900   \n",
      "\n",
      "      value__absolute_maximum  value__minimum  \n",
      "3677                 0.320000        0.271000  \n",
      "1421                14.713200        9.949250  \n",
      "2566                13.433400        6.865460  \n",
      "1341                 6.216560        4.441300  \n",
      "1169                 1.511000       -1.511000  \n",
      "...                       ...             ...  \n",
      "1158               106.374600       21.511300  \n",
      "1196                 2.980000       -0.325000  \n",
      "1374                17.112762       14.404842  \n",
      "897                  7.682220       -7.682220  \n",
      "3430                 2.385900        1.027950  \n",
      "\n",
      "[2722 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge extracted features with original dataset\n",
    "X_train_enhanced = pd.concat([X_train, extracted_features], axis=1)\n",
    "print(X_train_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEC 2019                     0\n",
       "DEC 2020                     0\n",
       "DEC 2021                     0\n",
       "DEC 2022                     0\n",
       "value__sum_values            0\n",
       "value__median                0\n",
       "value__mean                  0\n",
       "value__length                0\n",
       "value__standard_deviation    0\n",
       "value__variance              0\n",
       "value__root_mean_square      0\n",
       "value__maximum               0\n",
       "value__absolute_maximum      0\n",
       "value__minimum               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enhanced.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:04<00:00,  4.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Repeat for X_test\n",
    "X_test_long = X_test.copy()\n",
    "X_test_long[\"id\"] = np.arange(len(X_test))\n",
    "X_test_long = X_test_long.melt(id_vars=[\"id\"], var_name=\"time\", value_name=\"value\")\n",
    "\n",
    "extracted_features_test = extract_features(X_test_long, column_id=\"id\", column_sort=\"time\",\n",
    "                                           default_fc_parameters=MinimalFCParameters())\n",
    "\n",
    "# # Drop NaN columns and match train columns\n",
    "# extracted_features_test = extracted_features_test.dropna(axis=1)\n",
    "# Reindex test features to match train features (fill missing ones with 0)\n",
    "extracted_features_test = extracted_features_test.reindex(columns=X_train_enhanced.columns[1:], fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DEC 2020  DEC 2021  DEC 2022  value__sum_values  value__median  \\\n",
      "0           0         0         0            5.77085       1.399175   \n",
      "1           0         0         0            4.41397       1.044635   \n",
      "2           0         0         0         6288.31000    1464.030000   \n",
      "3           0         0         0           73.83039      19.643405   \n",
      "4           0         0         0          130.46339      32.172275   \n",
      "..        ...       ...       ...                ...            ...   \n",
      "676         0         0         0          322.34943      80.410430   \n",
      "677         0         0         0          109.14543      26.835690   \n",
      "678         0         0         0           31.20291       7.997035   \n",
      "679         0         0         0            4.79447       1.159435   \n",
      "680         0         0         0          685.06859     171.480970   \n",
      "\n",
      "     value__mean  value__length  value__standard_deviation  value__variance  \\\n",
      "0       1.442712            4.0                   0.328138     1.076742e-01   \n",
      "1       1.103492            4.0                   0.340708     1.160822e-01   \n",
      "2    1572.077500            4.0                1548.569196     2.398067e+06   \n",
      "3      18.457597            4.0                   3.288051     1.081128e+01   \n",
      "4      32.615848            4.0                   3.255020     1.059516e+01   \n",
      "..           ...            ...                        ...              ...   \n",
      "676    80.587358            4.0                  10.348015     1.070814e+02   \n",
      "677    27.286358            4.0                   2.350565     5.525158e+00   \n",
      "678     7.800727            4.0                   1.360573     1.851159e+00   \n",
      "679     1.198618            4.0                   0.452714     2.049500e-01   \n",
      "680   171.267147            4.0                   6.917931     4.785776e+01   \n",
      "\n",
      "     value__root_mean_square  value__maximum  value__absolute_maximum  \\\n",
      "0                   1.479559         1.86750                  1.86750   \n",
      "1                   1.154893         1.60380                  1.60380   \n",
      "2                2206.693051      3828.60000               3828.60000   \n",
      "3                  18.748178        21.59784                 21.59784   \n",
      "4                  32.777869        36.75240                 36.75240   \n",
      "..                       ...             ...                      ...   \n",
      "676                81.249022        95.06070                 95.06070   \n",
      "677                27.387414        30.99150                 30.99150   \n",
      "678                 7.918492         9.33840                  9.33840   \n",
      "679                 1.281263         1.80810                  1.80810   \n",
      "680               171.406807       180.62415                180.62415   \n",
      "\n",
      "     value__minimum  \n",
      "0           1.10500  \n",
      "1           0.72090  \n",
      "2        -468.35000  \n",
      "3          12.94574  \n",
      "4          29.36644  \n",
      "..              ...  \n",
      "676        66.46787  \n",
      "677        24.48255  \n",
      "678         5.87044  \n",
      "679         0.66750  \n",
      "680       161.48250  \n",
      "\n",
      "[681 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_test.index = X_test.index  # Align index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DEC 2019   DEC 2020    DEC 2021    DEC 2022  DEC 2020  DEC 2021  \\\n",
      "304      1.14187    1.10500     1.65648     1.86750         0         0   \n",
      "1591     0.72090    0.87040     1.21887     1.60380         0         0   \n",
      "2245  1068.00000 -468.35000  1860.06000  3828.60000         0         0   \n",
      "451     21.59784   19.33425    12.94574    19.95256         0         0   \n",
      "500     29.36644   29.49670    34.84785    36.75240         0         0   \n",
      "...          ...        ...         ...         ...       ...       ...   \n",
      "2623    66.46787   77.29390    83.52696    95.06070         0         0   \n",
      "2528    26.60655   24.48255    27.06483    30.99150         0         0   \n",
      "3536     5.87044    7.21055     8.78352     9.33840         0         0   \n",
      "2410     0.66750    0.87380     1.44507     1.80810         0         0   \n",
      "2222   173.48681  180.62415   169.47513   161.48250         0         0   \n",
      "\n",
      "      DEC 2022  value__sum_values  value__median  value__mean  value__length  \\\n",
      "304          0            5.77085       1.399175     1.442712            4.0   \n",
      "1591         0            4.41397       1.044635     1.103492            4.0   \n",
      "2245         0         6288.31000    1464.030000  1572.077500            4.0   \n",
      "451          0           73.83039      19.643405    18.457597            4.0   \n",
      "500          0          130.46339      32.172275    32.615848            4.0   \n",
      "...        ...                ...            ...          ...            ...   \n",
      "2623         0          322.34943      80.410430    80.587358            4.0   \n",
      "2528         0          109.14543      26.835690    27.286358            4.0   \n",
      "3536         0           31.20291       7.997035     7.800727            4.0   \n",
      "2410         0            4.79447       1.159435     1.198618            4.0   \n",
      "2222         0          685.06859     171.480970   171.267147            4.0   \n",
      "\n",
      "      value__standard_deviation  value__variance  value__root_mean_square  \\\n",
      "304                    0.328138     1.076742e-01                 1.479559   \n",
      "1591                   0.340708     1.160822e-01                 1.154893   \n",
      "2245                1548.569196     2.398067e+06              2206.693051   \n",
      "451                    3.288051     1.081128e+01                18.748178   \n",
      "500                    3.255020     1.059516e+01                32.777869   \n",
      "...                         ...              ...                      ...   \n",
      "2623                  10.348015     1.070814e+02                81.249022   \n",
      "2528                   2.350565     5.525158e+00                27.387414   \n",
      "3536                   1.360573     1.851159e+00                 7.918492   \n",
      "2410                   0.452714     2.049500e-01                 1.281263   \n",
      "2222                   6.917931     4.785776e+01               171.406807   \n",
      "\n",
      "      value__maximum  value__absolute_maximum  value__minimum  \n",
      "304          1.86750                  1.86750         1.10500  \n",
      "1591         1.60380                  1.60380         0.72090  \n",
      "2245      3828.60000               3828.60000      -468.35000  \n",
      "451         21.59784                 21.59784        12.94574  \n",
      "500         36.75240                 36.75240        29.36644  \n",
      "...              ...                      ...             ...  \n",
      "2623        95.06070                 95.06070        66.46787  \n",
      "2528        30.99150                 30.99150        24.48255  \n",
      "3536         9.33840                  9.33840         5.87044  \n",
      "2410         1.80810                  1.80810         0.66750  \n",
      "2222       180.62415                180.62415       161.48250  \n",
      "\n",
      "[681 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test_enhanced = pd.concat([X_test, extracted_features_test], axis=1)\n",
    "print(X_test_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2722, 14)\n",
      "(681, 14)\n",
      "(2722, 1)\n",
      "(681, 1)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate columns by keeping only the first occurrence\n",
    "X_train_enhanced = X_train_enhanced.loc[:, ~X_train_enhanced.columns.duplicated()]\n",
    "X_test_enhanced = X_test_enhanced.loc[:, ~X_test_enhanced.columns.duplicated()]\n",
    "\n",
    "# Ensure test features match train features (fix column mismatch)\n",
    "X_test_enhanced = X_test_enhanced.reindex(columns=X_train_enhanced.columns, fill_value=0)\n",
    "\n",
    "# Now apply StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_enhanced)\n",
    "print(X_train_scaled.shape)\n",
    "X_test_scaled = scaler_X.transform(X_test_enhanced)\n",
    "print(X_test_scaled.shape)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "print(y_train_scaled.shape)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "print(y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarek\\Downloads\\CodeChallenge-ML-Engineer-main\\CodeChallenge-ML-Engineer-main\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 60 is smaller than n_iter=200. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Best Parameters: {'weights': 'distance', 'p': 1, 'n_neighbors': 4, 'metric': 'euclidean'}\n",
      "Best KNN MAE: 53.90655446630941\n",
      "Best KNN R² Score: 0.6766353250247927\n"
     ]
    }
   ],
   "source": [
    "### 3. Hyperparameter Tuning Using RandomizedSearchCV ###\n",
    "param_dist = {\n",
    "    \"n_neighbors\": [1, 2, 3, 4, 5],  # Randomly choose from 3 to 20 neighbors\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize KNN\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Perform Randomized Search with 5-fold CV\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=200, \n",
    "                                   cv=10, scoring=\"r2\", verbose=1, \n",
    "                                   n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_knn = random_search.best_estimator_\n",
    "\n",
    "### 4. Predict and Evaluate the Best KNN Model ###\n",
    "# Predict on the test set\n",
    "y_pred_scaled = best_knn.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "mae = mean_absolute_error(y_test_original, y_pred)\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "print(f\"Best KNN MAE: {mae}\")\n",
    "print(f\"Best KNN R² Score: {r2}\")\n",
    "\n",
    "# ### 5. Show Actual vs Predicted Values ###\n",
    "# results = pd.DataFrame({\n",
    "#     \"Actual DEC 2019\": y_test_original[:, 0],\n",
    "#     \"Predicted DEC 2019\": y_pred[:, 0],\n",
    "#     \"Actual DEC 2020\": y_test_original[:, 1],\n",
    "#     \"Predicted DEC 2020\": y_pred[:, 1],\n",
    "#     \"Actual DEC 2021\": y_test_original[:, 2],\n",
    "#     \"Predicted DEC 2021\": y_pred[:, 2],\n",
    "#     \"Actual DEC 2022\": y_test_original[:, 3],\n",
    "#     \"Predicted DEC 2022\": y_pred[:, 3],\n",
    "#     \"Actual DEC 2023\": y_test_original[:, 4],\n",
    "#     \"Predicted DEC 2023\": y_pred[:, 4],\n",
    "# })\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_original shape: (681, 1)\n",
      "y_pred shape: (681, 1)\n",
      "        Actual    Predicted\n",
      "0       49.931      67.0204\n",
      "1       38.912      59.2492\n",
      "2     5200.000   14965.1976\n",
      "3    22399.170   37797.8130\n",
      "4      224.553    7034.7510\n",
      "..         ...          ...\n",
      "676   2346.330  254341.2378\n",
      "677     30.560     978.4008\n",
      "678     33.169      58.1430\n",
      "679     67.914     183.0050\n",
      "680    115.807     495.3848\n",
      "\n",
      "[681 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_test_original and y_pred are 2D arrays\n",
    "if y_test_original.ndim == 1:\n",
    "    y_test_original = y_test_original.reshape(-1, 1)\n",
    "\n",
    "if y_pred.ndim == 1:\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(\"y_test_original shape:\", y_test_original.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "# Now construct the DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test_original[:, 0],\n",
    "    \"Predicted\": y_pred[:, 0],\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define KNN Regressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5, weights=\"distance\", metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "Best KNN MAE: 36273.94785827254\n",
      "Best KNN R² Score: -1.184354421856766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import scipy.stats as st\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "param_dist = {\n",
    "    \"n_neighbors\": st.randint(1, 20),  # Randomly choose from 3 to 20 neighbors\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize KNN Regressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Perform Randomized Search with 5-fold Cross-Validation\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=20, \n",
    "                                   cv=5, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Get best model\n",
    "best_knn = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_scaled = best_knn.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best KNN MAE: {mae}\")\n",
    "print(f\"Best KNN R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 15, 'p': 1, 'weights': 'distance'}\n",
      "Best KNN MAE: 38242.055144575585\n",
      "Best KNN R² Score: -1.4173407798189028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7, 10, 15],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "    \"p\": [1, 2]  # Only used when metric is 'minkowski'\n",
    "}\n",
    "\n",
    "# Initialize KNN Regressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Perform Grid Search with 5-fold Cross-Validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_scaled = best_knn.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best KNN MAE: {mae}\")\n",
    "print(f\"Best KNN R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(metric=&#x27;euclidean&#x27;, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(metric=&#x27;euclidean&#x27;, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(metric='euclidean', weights='distance')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "knn_regressor.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_scaled = knn_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions to the original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 40265.50418517577\n",
      "R² Score: -3.9335915560509753\n",
      "    Actual DEC 2019  Predicted DEC 2019  Actual DEC 2020  Predicted DEC 2020  \\\n",
      "0        236817.569           10.928122        76023.111            7.745547   \n",
      "1             3.850        89202.354560            5.691        91726.045916   \n",
      "2           447.894         3928.556774          447.453         9491.846384   \n",
      "3          3191.427         1626.122194         2139.522         3074.440110   \n",
      "4           703.000        23027.833982          702.000        18363.224422   \n",
      "..              ...                 ...              ...                 ...   \n",
      "66          125.840           16.487058          170.490           10.898847   \n",
      "67          674.244         5166.003341          631.327        10682.075356   \n",
      "68         1745.472        43363.559504         2059.747        46918.398931   \n",
      "69           55.466         3226.449273           65.945         3707.000622   \n",
      "70         5580.286        20490.643814         5851.000        17935.186274   \n",
      "\n",
      "    Actual DEC 2021  Predicted DEC 2021  Actual DEC 2022  Predicted DEC 2022  \\\n",
      "0         97128.892           16.773837       234021.865           12.726380   \n",
      "1            12.125        98724.639142           38.139        71676.953672   \n",
      "2           471.973        11277.050358          348.996        12351.332345   \n",
      "3          2544.880         2448.651331         3299.795         2358.598535   \n",
      "4          1028.000        19105.037559         1545.000        22443.259420   \n",
      "..              ...                 ...              ...                 ...   \n",
      "66          367.321           25.661902          421.534           17.281483   \n",
      "67          697.511        21221.303634          567.834        10959.924872   \n",
      "68         3205.553        24801.312664         4523.742        27844.457596   \n",
      "69           27.258         3353.599815           61.975         7028.771826   \n",
      "70         6918.000        30325.151475         6787.000        31994.237275   \n",
      "\n",
      "    Actual DEC 2023  Predicted DEC 2023  \n",
      "0        158470.070           12.710494  \n",
      "1            22.787        64095.723813  \n",
      "2          3100.921         7082.174260  \n",
      "3          4266.889         2478.278975  \n",
      "4          1042.000        29406.970460  \n",
      "..              ...                 ...  \n",
      "66          505.447           16.480350  \n",
      "67          484.492        21404.784619  \n",
      "68         7971.180        30809.692075  \n",
      "69           54.304         6924.681132  \n",
      "70         7877.000        16854.424195  \n",
      "\n",
      "[71 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test_original, y_pred)\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Create a DataFrame to compare actual vs predicted values\n",
    "results = pd.DataFrame({\n",
    "    \"Actual DEC 2019\": y_test_original[:, 0],\n",
    "    \"Predicted DEC 2019\": y_pred[:, 0],\n",
    "    \"Actual DEC 2020\": y_test_original[:, 1],\n",
    "    \"Predicted DEC 2020\": y_pred[:, 1],\n",
    "    \"Actual DEC 2021\": y_test_original[:, 2],\n",
    "    \"Predicted DEC 2021\": y_pred[:, 2],\n",
    "    \"Actual DEC 2022\": y_test_original[:, 3],\n",
    "    \"Predicted DEC 2022\": y_pred[:, 3],\n",
    "    \"Actual DEC 2023\": y_test_original[:, 4],\n",
    "    \"Predicted DEC 2023\": y_pred[:, 4],\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=600, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=600, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=600, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost Regressor model\n",
    "xgb_model = XGBRegressor(n_estimators=600, learning_rate=0.0001, max_depth=10, random_state=42, )\n",
    "xgb_model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_scaled = xgb_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 46481.08160484156\n",
      "R² Score: -1.1027124576897223\n",
      "    Actual DEC 2019  Predicted DEC 2019  Actual DEC 2020  Predicted DEC 2020  \\\n",
      "0        236817.569        42322.742188        76023.111        28882.871094   \n",
      "1             3.850        44495.617188            5.691        29838.621094   \n",
      "2           447.894        40734.351562          447.453        39455.878906   \n",
      "3          3191.427        42322.742188         2139.522        28882.871094   \n",
      "4           703.000       208164.656250          702.000       109461.625000   \n",
      "..              ...                 ...              ...                 ...   \n",
      "66          125.840        42322.742188          170.490        28882.871094   \n",
      "67          674.244        28289.187500          631.327        30354.292969   \n",
      "68         1745.472        26314.472656         2059.747        22491.601562   \n",
      "69           55.466        42322.742188           65.945        28882.871094   \n",
      "70         5580.286        44495.617188         5851.000        29633.080078   \n",
      "\n",
      "    Actual DEC 2021  Predicted DEC 2021  Actual DEC 2022  Predicted DEC 2022  \\\n",
      "0         97128.892        52903.375000       234021.865        48084.035156   \n",
      "1            12.125        41251.714844           38.139        46343.128906   \n",
      "2           471.973        33959.761719          348.996        56631.531250   \n",
      "3          2544.880        45846.566406         3299.795        40484.964844   \n",
      "4          1028.000        75127.328125         1545.000       120377.375000   \n",
      "..              ...                 ...              ...                 ...   \n",
      "66          367.321        52903.375000          421.534        48084.035156   \n",
      "67          697.511        33959.761719          567.834        40485.316406   \n",
      "68         3205.553        30058.982422         4523.742        34296.828125   \n",
      "69           27.258        33959.761719           61.975        40484.964844   \n",
      "70         6918.000        41251.714844         6787.000        45969.257812   \n",
      "\n",
      "    Actual DEC 2023  Predicted DEC 2023  \n",
      "0        158470.070        47215.765625  \n",
      "1            22.787        46511.699219  \n",
      "2          3100.921        46511.699219  \n",
      "3          4266.889        47215.765625  \n",
      "4          1042.000        46511.699219  \n",
      "..              ...                 ...  \n",
      "66          505.447        47215.765625  \n",
      "67          484.492        46511.699219  \n",
      "68         7971.180        46511.699219  \n",
      "69           54.304        47215.765625  \n",
      "70         7877.000        41530.046875  \n",
      "\n",
      "[71 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predictions\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 5))\n",
    "\n",
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)\n",
    "\n",
    "# Show actual vs. predicted values\n",
    "results = pd.DataFrame({\n",
    "    \"Actual DEC 2019\": y_test.values[:, 0],\n",
    "    \"Predicted DEC 2019\": y_pred[:, 0],\n",
    "    \"Actual DEC 2020\": y_test.values[:, 1],\n",
    "    \"Predicted DEC 2020\": y_pred[:, 1],\n",
    "    \"Actual DEC 2021\": y_test.values[:, 2],\n",
    "    \"Predicted DEC 2021\": y_pred[:, 2],\n",
    "    \"Actual DEC 2022\": y_test.values[:, 3],\n",
    "    \"Predicted DEC 2022\": y_pred[:, 3],\n",
    "    \"Actual DEC 2023\": y_test.values[:, 4],\n",
    "    \"Predicted DEC 2023\": y_pred[:, 4],\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 17:27:00,916] A new study created in memory with name: no-name-34bca15e-18ab-4d44-a501-3ecff2fcfd75\n",
      "[I 2025-01-30 17:27:01,524] Trial 0 finished with value: 49880.70287303724 and parameters: {'n_estimators': 406, 'learning_rate': 0.032227657827331516, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.9169107333515552, 'colsample_bytree': 0.7220966376272845, 'gamma': 0.3034024126060919, 'lambda': 8.124641798806213, 'alpha': 4.715928866248303}. Best is trial 0 with value: 49880.70287303724.\n",
      "[I 2025-01-30 17:27:02,145] Trial 1 finished with value: 49482.04489032241 and parameters: {'n_estimators': 478, 'learning_rate': 0.0690604392027491, 'max_depth': 14, 'min_child_weight': 12, 'subsample': 0.7738349900768076, 'colsample_bytree': 0.8481107798942644, 'gamma': 1.7443841882049176, 'lambda': 9.656479016198944, 'alpha': 8.037781619290708}. Best is trial 1 with value: 49482.04489032241.\n",
      "[I 2025-01-30 17:27:03,108] Trial 2 finished with value: 50464.491965316905 and parameters: {'n_estimators': 554, 'learning_rate': 0.06891991030679559, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.873470056158008, 'colsample_bytree': 0.9138365160466904, 'gamma': 4.4419545090531685, 'lambda': 6.3556865407712895, 'alpha': 4.346112389652623}. Best is trial 1 with value: 49482.04489032241.\n",
      "[I 2025-01-30 17:27:03,876] Trial 3 finished with value: 55042.827911625325 and parameters: {'n_estimators': 384, 'learning_rate': 0.04286327915237388, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.7371122196075943, 'colsample_bytree': 0.8390851247755347, 'gamma': 1.2608836894645936, 'lambda': 6.756129259433689, 'alpha': 2.1653726411641347}. Best is trial 1 with value: 49482.04489032241.\n",
      "[I 2025-01-30 17:27:04,164] Trial 4 finished with value: 49068.56600088029 and parameters: {'n_estimators': 222, 'learning_rate': 0.0733159316722299, 'max_depth': 13, 'min_child_weight': 12, 'subsample': 0.9116792244936522, 'colsample_bytree': 0.7716469576806387, 'gamma': 2.9406622153229938, 'lambda': 7.139412596391285, 'alpha': 5.53022315596116}. Best is trial 4 with value: 49068.56600088029.\n",
      "[I 2025-01-30 17:27:04,480] Trial 5 finished with value: 47216.486968232835 and parameters: {'n_estimators': 219, 'learning_rate': 0.02161264544444994, 'max_depth': 21, 'min_child_weight': 5, 'subsample': 0.9007909271020681, 'colsample_bytree': 0.7870847717997589, 'gamma': 1.5648674778447058, 'lambda': 4.908632151558604, 'alpha': 2.156286346170666}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:05,058] Trial 6 finished with value: 49977.52882431228 and parameters: {'n_estimators': 502, 'learning_rate': 0.06960732865016697, 'max_depth': 16, 'min_child_weight': 5, 'subsample': 0.7168817531896831, 'colsample_bytree': 0.7632671444574413, 'gamma': 4.746901193233681, 'lambda': 3.9307585764220008, 'alpha': 4.416057855814756}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:05,646] Trial 7 finished with value: 48988.66067720071 and parameters: {'n_estimators': 563, 'learning_rate': 0.06124051766759354, 'max_depth': 11, 'min_child_weight': 11, 'subsample': 0.9633793663807367, 'colsample_bytree': 0.7267858877996171, 'gamma': 4.090492341545494, 'lambda': 9.26703664236644, 'alpha': 8.875973556163292}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:05,861] Trial 8 finished with value: 52160.060802151536 and parameters: {'n_estimators': 179, 'learning_rate': 0.03199669241168799, 'max_depth': 21, 'min_child_weight': 12, 'subsample': 0.8119318641139984, 'colsample_bytree': 0.9192980427732811, 'gamma': 0.929353354773978, 'lambda': 1.4412987161602238, 'alpha': 5.295405732065696}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:06,658] Trial 9 finished with value: 61202.47606758606 and parameters: {'n_estimators': 543, 'learning_rate': 0.07408078148745084, 'max_depth': 15, 'min_child_weight': 7, 'subsample': 0.8386088841616098, 'colsample_bytree': 0.9687572733001357, 'gamma': 0.8116731907503888, 'lambda': 7.409222929316243, 'alpha': 2.8152902953345595}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:06,878] Trial 10 finished with value: 102379.29865378523 and parameters: {'n_estimators': 100, 'learning_rate': 0.006358502878771745, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.9964844570220542, 'colsample_bytree': 0.8029971230865792, 'gamma': 2.6972537976937403, 'lambda': 3.9323993085623954, 'alpha': 0.10265692337525145}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:07,405] Trial 11 finished with value: 53456.78934146128 and parameters: {'n_estimators': 271, 'learning_rate': 0.09411706952587794, 'max_depth': 24, 'min_child_weight': 8, 'subsample': 0.9955826794356669, 'colsample_bytree': 0.706158939166174, 'gamma': 3.648731567737097, 'lambda': 5.020528542807988, 'alpha': 9.90825122746329}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:07,905] Trial 12 finished with value: 86778.44724207747 and parameters: {'n_estimators': 296, 'learning_rate': 0.0038749676247853276, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9376749089232685, 'colsample_bytree': 0.7553053911296295, 'gamma': 1.9379059236367497, 'lambda': 9.771607237830326, 'alpha': 7.421168670707219}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:08,741] Trial 13 finished with value: 54617.33084515467 and parameters: {'n_estimators': 333, 'learning_rate': 0.020698765148822827, 'max_depth': 18, 'min_child_weight': 9, 'subsample': 0.9529207248669753, 'colsample_bytree': 0.8103601176431768, 'gamma': 3.574231644495429, 'lambda': 1.974603745442539, 'alpha': 0.6969363511051876}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:09,460] Trial 14 finished with value: 48614.56435246479 and parameters: {'n_estimators': 596, 'learning_rate': 0.046376541645683445, 'max_depth': 24, 'min_child_weight': 3, 'subsample': 0.8757301394088481, 'colsample_bytree': 0.734074678248874, 'gamma': 3.735663179470392, 'lambda': 5.127518476287847, 'alpha': 9.67973184648554}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:09,691] Trial 15 finished with value: 53496.90009128521 and parameters: {'n_estimators': 130, 'learning_rate': 0.04764773908384578, 'max_depth': 24, 'min_child_weight': 3, 'subsample': 0.8806766363607985, 'colsample_bytree': 0.8022967836673359, 'gamma': 2.2042402960543566, 'lambda': 5.196361501195733, 'alpha': 6.7322989231581065}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:10,362] Trial 16 finished with value: 51321.39026185595 and parameters: {'n_estimators': 434, 'learning_rate': 0.01952371078314927, 'max_depth': 21, 'min_child_weight': 6, 'subsample': 0.8243042264950288, 'colsample_bytree': 0.8909428249030755, 'gamma': 3.298799365253017, 'lambda': 2.7391240542870188, 'alpha': 2.6545132670662457}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:10,927] Trial 17 finished with value: 49373.54873286438 and parameters: {'n_estimators': 226, 'learning_rate': 0.036050089731810016, 'max_depth': 18, 'min_child_weight': 3, 'subsample': 0.8782050723399589, 'colsample_bytree': 0.7458817530659194, 'gamma': 1.511752840927314, 'lambda': 3.5941611952468895, 'alpha': 1.1774316723922191}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:11,725] Trial 18 finished with value: 50059.025646410446 and parameters: {'n_estimators': 593, 'learning_rate': 0.018656173663052816, 'max_depth': 23, 'min_child_weight': 6, 'subsample': 0.8004760912085888, 'colsample_bytree': 0.7819401985017026, 'gamma': 2.2581997392839837, 'lambda': 5.8476892140187, 'alpha': 3.5777260352348286}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:12,156] Trial 19 finished with value: 53057.63518971308 and parameters: {'n_estimators': 326, 'learning_rate': 0.05788621270157507, 'max_depth': 19, 'min_child_weight': 1, 'subsample': 0.8515095888096975, 'colsample_bytree': 0.8789325667120031, 'gamma': 0.11326495455334995, 'lambda': 4.731603542397266, 'alpha': 6.271279302507699}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:12,411] Trial 20 finished with value: 50333.13100620599 and parameters: {'n_estimators': 171, 'learning_rate': 0.08855079471033596, 'max_depth': 22, 'min_child_weight': 4, 'subsample': 0.9073400249307035, 'colsample_bytree': 0.7011461435474655, 'gamma': 4.114205957181464, 'lambda': 8.190578612455866, 'alpha': 9.402403493270343}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:13,106] Trial 21 finished with value: 49223.11303195423 and parameters: {'n_estimators': 597, 'learning_rate': 0.05626948053676114, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.9592447624509164, 'colsample_bytree': 0.7338183928718948, 'gamma': 4.0620868253750615, 'lambda': 8.764951542441985, 'alpha': 8.751013770774108}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:13,677] Trial 22 finished with value: 50412.58774036092 and parameters: {'n_estimators': 468, 'learning_rate': 0.056791161327655756, 'max_depth': 17, 'min_child_weight': 8, 'subsample': 0.9680535334422237, 'colsample_bytree': 0.7316517048524328, 'gamma': 4.924050514964595, 'lambda': 5.756248792888055, 'alpha': 8.741942630591115}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:14,341] Trial 23 finished with value: 47816.11039480635 and parameters: {'n_estimators': 530, 'learning_rate': 0.0823648705244491, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.930665619492052, 'colsample_bytree': 0.7845612882016101, 'gamma': 3.029145104053703, 'lambda': 4.380318279887662, 'alpha': 7.675923681771951}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:15,006] Trial 24 finished with value: 48760.28463006162 and parameters: {'n_estimators': 522, 'learning_rate': 0.08143869344500748, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.8959363381490753, 'colsample_bytree': 0.8213737786932707, 'gamma': 3.061717011532599, 'lambda': 3.037213763602245, 'alpha': 7.8035441164893244}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:15,541] Trial 25 finished with value: 50879.68787799296 and parameters: {'n_estimators': 446, 'learning_rate': 0.0423581864056041, 'max_depth': 23, 'min_child_weight': 2, 'subsample': 0.9261760377807324, 'colsample_bytree': 0.7810877672813042, 'gamma': 2.4513751652138813, 'lambda': 4.296575100723677, 'alpha': 9.956953160129702}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:15,996] Trial 26 finished with value: 54374.47839295775 and parameters: {'n_estimators': 372, 'learning_rate': 0.012031894625202592, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.857424764144298, 'colsample_bytree': 0.7873365677967876, 'gamma': 3.6045014022124784, 'lambda': 4.553286670543328, 'alpha': 6.983072064602398}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:16,393] Trial 27 finished with value: 51756.90053041373 and parameters: {'n_estimators': 264, 'learning_rate': 0.027344138246038843, 'max_depth': 21, 'min_child_weight': 5, 'subsample': 0.8963616147230031, 'colsample_bytree': 0.8354465604372616, 'gamma': 2.748313798878935, 'lambda': 2.9984126313424264, 'alpha': 6.027695785179759}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:17,062] Trial 28 finished with value: 47951.48800950704 and parameters: {'n_estimators': 522, 'learning_rate': 0.082378696136476, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.9372496828764113, 'colsample_bytree': 0.7584045840421272, 'gamma': 3.298774127403612, 'lambda': 6.111185024324945, 'alpha': 8.12590506462126}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:17,773] Trial 29 finished with value: 51851.36220513427 and parameters: {'n_estimators': 415, 'learning_rate': 0.09609045014918485, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.9350095545984574, 'colsample_bytree': 0.8686777729307943, 'gamma': 0.6484294006741431, 'lambda': 6.2014975717930545, 'alpha': 3.9373478928879404}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:18,732] Trial 30 finished with value: 50084.792939612686 and parameters: {'n_estimators': 499, 'learning_rate': 0.08322921276134443, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9828226419060931, 'colsample_bytree': 0.9995734644722678, 'gamma': 3.2435953858324917, 'lambda': 7.980039421798391, 'alpha': 7.652792853303466}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:19,575] Trial 31 finished with value: 47303.35412235915 and parameters: {'n_estimators': 532, 'learning_rate': 0.0815534592485937, 'max_depth': 19, 'min_child_weight': 3, 'subsample': 0.9243185536748093, 'colsample_bytree': 0.749221661067967, 'gamma': 3.7855414521106168, 'lambda': 5.325326101561781, 'alpha': 8.319631119622727}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:20,295] Trial 32 finished with value: 49445.51609181338 and parameters: {'n_estimators': 472, 'learning_rate': 0.0853941432277703, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.9342254531259391, 'colsample_bytree': 0.7602631105597771, 'gamma': 1.8814932096892365, 'lambda': 5.657788525591798, 'alpha': 8.182203461020848}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:20,906] Trial 33 finished with value: 47772.8281787412 and parameters: {'n_estimators': 512, 'learning_rate': 0.09998021647915578, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.9162336731621639, 'colsample_bytree': 0.7904427529732632, 'gamma': 4.4690065968859205, 'lambda': 6.387996097644532, 'alpha': 8.36940443889891}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:21,609] Trial 34 finished with value: 47293.55705880282 and parameters: {'n_estimators': 554, 'learning_rate': 0.09954069812555599, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.9083838538203485, 'colsample_bytree': 0.7892652806594261, 'gamma': 4.573687869465937, 'lambda': 6.707841330104104, 'alpha': 7.059627004995046}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:22,428] Trial 35 finished with value: 47873.365539832754 and parameters: {'n_estimators': 562, 'learning_rate': 0.09160842750238579, 'max_depth': 19, 'min_child_weight': 5, 'subsample': 0.9053662609785849, 'colsample_bytree': 0.8245785571232277, 'gamma': 4.519573004425374, 'lambda': 6.621023327896484, 'alpha': 6.866944650836562}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:23,093] Trial 36 finished with value: 48349.1146421655 and parameters: {'n_estimators': 503, 'learning_rate': 0.09911002157781396, 'max_depth': 17, 'min_child_weight': 4, 'subsample': 0.8911926094615288, 'colsample_bytree': 0.7993169080348441, 'gamma': 4.561641981169728, 'lambda': 7.215644739705617, 'alpha': 6.017308556957122}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:23,674] Trial 37 finished with value: 48885.809852200706 and parameters: {'n_estimators': 406, 'learning_rate': 0.09781625696053006, 'max_depth': 20, 'min_child_weight': 6, 'subsample': 0.9176110659104992, 'colsample_bytree': 0.8621594696747167, 'gamma': 4.218388776446084, 'lambda': 6.813128191405485, 'alpha': 4.902709515433495}. Best is trial 5 with value: 47216.486968232835.\n",
      "[I 2025-01-30 17:27:24,360] Trial 38 finished with value: 46481.08160484156 and parameters: {'n_estimators': 571, 'learning_rate': 0.08916677726566508, 'max_depth': 19, 'min_child_weight': 5, 'subsample': 0.858721031496248, 'colsample_bytree': 0.850079314644279, 'gamma': 4.940554853719812, 'lambda': 7.661064349998632, 'alpha': 8.98994500225716}. Best is trial 38 with value: 46481.08160484156.\n",
      "[I 2025-01-30 17:27:24,972] Trial 39 finished with value: 47080.770503785214 and parameters: {'n_estimators': 559, 'learning_rate': 0.07645927942345293, 'max_depth': 22, 'min_child_weight': 7, 'subsample': 0.7657785759740744, 'colsample_bytree': 0.8517816676789929, 'gamma': 4.96119557124766, 'lambda': 8.191207171991909, 'alpha': 9.245260777472414}. Best is trial 38 with value: 46481.08160484156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 571, 'learning_rate': 0.08916677726566508, 'max_depth': 19, 'min_child_weight': 5, 'subsample': 0.858721031496248, 'colsample_bytree': 0.850079314644279, 'gamma': 4.940554853719812, 'lambda': 7.661064349998632, 'alpha': 8.98994500225716}\n",
      "Final MAE: 46481.08160484156\n",
      "Final R² Score: -1.1027124576897223\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define an objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 24),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'lambda': trial.suggest_float('lambda', 1, 10),\n",
    "        'alpha': trial.suggest_float('alpha', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    # Predict and calculate MAE\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 5))\n",
    "    \n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Run Optuna to find the best hyperparameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train final model with the best parameters\n",
    "xgb_model = XGBRegressor(**best_params, random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_scaled = xgb_model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 5))\n",
    "\n",
    "# Evaluate final model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Final MAE:\", mae)\n",
    "print(\"Final R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved at: C:/Users/tarek/Downloads/dataset-EUR-F82CE786-DD89-11EF-9680-C7EA406D2E00/Updated_Book1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_prefix_to_indicators(file_path, output_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Rename section columns for clarity\n",
    "    df.rename(columns={'SECTION': 'SELL_SIDE_SECTION', 'SECTION.1': 'BUY_SIDE_SECTION'}, inplace=True)\n",
    "    \n",
    "    # Identify SELL-SIDE and BUY-SIDE rows\n",
    "    sell_side_mask = df[\"SELL_SIDE_SECTION\"].notna()\n",
    "    buy_side_mask = df[\"BUY_SIDE_SECTION\"].notna()\n",
    "    \n",
    "    # Apply prefixes to financial indicators based on the section type\n",
    "    df.loc[sell_side_mask, \"SELL_SIDE_SECTION\"] = \"sell_\" + df.loc[sell_side_mask, \"SELL_SIDE_SECTION\"].astype(str)\n",
    "    df.loc[buy_side_mask, \"BUY_SIDE_SECTION\"] = \"buy_\" + df.loc[buy_side_mask, \"BUY_SIDE_SECTION\"].astype(str)\n",
    "    \n",
    "    # Save the updated file\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Updated file saved at: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"C:/Users/tarek/Downloads/dataset-EUR-F82CE786-DD89-11EF-9680-C7EA406D2E00/dataset-EUR-F82CE786-DD89-11EF-9680-C7EA406D2E00.xlsx\"  # Change this to your actual input file path\n",
    "output_file = \"C:/Users/tarek/Downloads/dataset-EUR-F82CE786-DD89-11EF-9680-C7EA406D2E00/Updated_Book1.csv\"  # Change this to your desired output file path\n",
    "add_prefix_to_indicators(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing necessary libraries since execution state was reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Creating the new Sell Side DataFrame\n",
    "sell_side_new_data = {\n",
    "    \"Gross Income_Sell\": [40.636, 66.684, 54.057, 42.949, -0.829],\n",
    "    \"EBIT_Sell\": [40.648, 66.684, 54.057, 43.522, -0.829],\n",
    "    \"EBITDA_Sell\": [41.501, 68.237, 55.366, 44.538, -0.572],\n",
    "    \"Net Income_Sell\": [27.04, 48.229, 41.489, 33.967, -0.876],\n",
    "    \"Cash & Short-Term Investments_Sell\": [113.873, 117.95, 109.937, 59.103, 11.377],\n",
    "    \"Total Assets_Sell\": [240.688, 252.334, 177.03, 145.761, 28.197],\n",
    "    \"Total Debt_Sell\": [0, 0, 0, 0, 0],\n",
    "    \"Net Debt_Sell\": [-113.873, -117.95, -109.937, -59.103, -11.377],\n",
    "    \"Total Liabilities_Sell\": [202.902, 214.547, 140.75, 115.929, 10.139],\n",
    "    \"Total Shareholders' Equity_Sell\": [37.786, 37.786, 36.28, 29.832, 18.058],\n",
    "}\n",
    "\n",
    "sell_side_new_df = pd.DataFrame(sell_side_new_data)\n",
    "\n",
    "# Creating the new Buy Side DataFrame\n",
    "buy_side_new_data = {\n",
    "    \"Gross Income_Buy\": [-71.147, -71.596, 58.811, -178.494, -322.412],\n",
    "    \"EBIT_Buy\": [-71.147, -71.596, 58.811, -178.494, -322.412],\n",
    "    \"EBITDA_Buy\": [634.55, 678.226, 801.342, 578.353, 388.168],\n",
    "    \"Net Income_Buy\": [-332.893, -479.909, -583.283, -753.911, -821.683],\n",
    "    \"Cash & Short-Term Investments_Buy\": [976.819, 871.371, 911.627, 542.463, 201.438],\n",
    "    \"Total Assets_Buy\": [4482.299, 4587.999, 4648.123, 4514.745, 4788.735],\n",
    "    \"Total Debt_Buy\": [4.296, 3.237, 404.201, 621.615, 730.207],\n",
    "    \"Net Debt_Buy\": [-972.522, -868.135, -507.425, 79.152, 528.768],\n",
    "    \"Total Liabilities_Buy\": [8762.065, 8671.28, 8268.565, 7565.322, 7086.162],\n",
    "    \"Total Shareholders' Equity_Buy\": [-4279.766, -4083.281, -3620.441, -3050.577, -2297.426],\n",
    "}\n",
    "\n",
    "buy_side_new_df = pd.DataFrame(buy_side_new_data)\n",
    "\n",
    "# Extracting X (Sell Side) and y (Buy Side)\n",
    "X_new = sell_side_new_df\n",
    "y_new = buy_side_new_df\n",
    "\n",
    "# Standardizing the features for better regression performance\n",
    "scaler_X_new = StandardScaler()\n",
    "scaler_y_new = StandardScaler()\n",
    "X_new_scaled = scaler_X_new.fit_transform(X_new)\n",
    "y_new_scaled = scaler_y_new.fit_transform(y_new)\n",
    "\n",
    "# Splitting into training and testing sets (leave-one-out validation due to small dataset)\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new_scaled, y_new_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training a Ridge Regression model\n",
    "model_new = Ridge(alpha=1.0)\n",
    "model_new.fit(X_train_new, y_train_new)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_scaled_new = model_new.predict(X_test_new)\n",
    "\n",
    "# Inversing the scaling to get real-world values\n",
    "y_pred_new = scaler_y_new.inverse_transform(y_pred_scaled_new)\n",
    "y_test_real_new = scaler_y_new.inverse_transform(y_test_new)\n",
    "\n",
    "# Creating a DataFrame to compare actual vs predicted values\n",
    "results_new = pd.DataFrame(y_test_real_new, columns=buy_side_new_df.columns, index=buy_side_new_df.iloc[-len(y_test_real_new):].index)\n",
    "results_new[\"Predicted_\" + results_new.columns] = y_pred_new\n",
    "\n",
    "# Saving the results to a CSV file\n",
    "results_new.to_csv(\"C:/Users/tarek/Downloads/actual_vs_predicted_ridge.csv\", index=False)\n",
    "\n",
    "# Evaluating the model with Mean Absolute Error\n",
    "mae_values_new = mean_absolute_error(y_test_real_new, y_pred_new, multioutput='raw_values')\n",
    "\n",
    "# Creating a DataFrame to show MAE for each indicator\n",
    "mae_df_new = pd.DataFrame({\"Indicator\": buy_side_new_df.columns, \"MAE\": mae_values_new})\n",
    "mae_df_new.to_csv(\"C:/Users/tarek/Downloads/mae_df_ridge.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
